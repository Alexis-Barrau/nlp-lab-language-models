{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "99466dec",
   "metadata": {},
   "source": [
    "# NLP Lab : Modèles de langue\n",
    "\n",
    "Dans ce tp, nous allons constuire les briques principales du modèle GPT2 et entrainer un petit modèle sur des poèmes de Victor Hugo. \n",
    "\n",
    "Les questions sont posées dans ce notebook, mais pour executer l'entrainement, il faudra modifier le ficher gpt_single_head.py\n",
    "\n",
    "\n",
    "## Données\n",
    "\n",
    "Les données d'entrainement sont un recueil de poèmes de Victor Hugo issu du site [gutenber.org](https://www.gutenberg.org/). \n",
    "\n",
    "Afin de réduire la complexité du modèle, nous allons modéliser le texte au niveau caractère. \n",
    "\n",
    "Questions:\n",
    ">* en utilisant [collections.Counter](https://docs.python.org/3/library/collections.html#collections.Counter), afficher le nombre de caractères différents dans le texte et la fréquence de chaque caractère."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "20c55852",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of characters in the file: 285222\n",
      "Number of character in counter: 285222\n",
      "101 different characters\n",
      "Counter({' ': 49127, 'e': 30253, 's': 17987, 'u': 14254, 'r': 14223, 't': 14071, 'a': 14048, 'n': 13725, 'i': 12828, 'o': 12653, 'l': 11638, '\\n': 8102, 'm': 6495, 'd': 6375, ',': 6077, 'c': 5074, 'p': 4206, \"'\": 3820, 'v': 3492, 'é': 2943, 'b': 2783, 'f': 2772, 'h': 2221, 'q': 1956, 'g': 1790, '.': 1420, 'x': 1154, 'L': 1147, '!': 1121, 'E': 1074, ';': 1043, '-': 1020, 'j': 890, 'D': 764, 'è': 725, 'à': 706, 'y': 660, 'I': 627, 'ê': 605, 'C': 593, 'S': 545, 'A': 530, 'Q': 503, 'z': 482, 'J': 471, 'O': 450, 'T': 441, 'P': 435, '?': 388, 'V': 383, 'â': 381, 'N': 362, 'M': 344, 'ù': 298, ':': 294, 'R': 240, 'î': 214, 'U': 208, 'ô': 159, 'X': 150, '1': 146, 'H': 116, 'F': 114, '5': 111, '8': 93, 'B': 78, '«': 74, 'É': 70, '»': 69, 'G': 67, '4': 64, 'û': 62, '3': 47, 'ç': 34, 'À': 33, 'ë': 32, 'ï': 31, '2': 30, '·': 26, 'Ê': 24, '6': 23, '7': 23, 'Ô': 19, '9': 19, 'È': 11, 'k': 10, '0': 10, '_': 8, 'Z': 7, 'Æ': 4, '[': 4, ']': 4, 'w': 3, 'K': 3, 'Y': 3, 'Ë': 2, '(': 2, ')': 2, 'Â': 2, 'Î': 1, 'W': 1})\n"
     ]
    }
   ],
   "source": [
    "import collections\n",
    "\n",
    "with open('data/hugo_contemplations.txt', 'r', encoding='utf-8') as f:\n",
    "    text = f.read()\n",
    "\n",
    "print(f'Number of characters in the file: {len(text)}')\n",
    "# here are all the unique characters that occur in this text\n",
    "counter = collections.Counter(text)\n",
    "chars = counter.keys()\n",
    "vocab_size = len(chars)\n",
    "\n",
    "print (f'Number of character in counter: {sum(counter.values())}')\n",
    "print (f'{len(chars)} different characters')\n",
    "print (counter)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee169e3b",
   "metadata": {},
   "source": [
    "### Encodage / décodage\n",
    "Afin de transformer le texte en vecteur pour le réseau de neurone, il faut encoder chaque caractère avec un entier. Les fonctions suivante opérent l'encodage et le décodage des caractères:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "2a938bbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a mapping from characters to integers\n",
    "stoi = { ch:i for i,ch in enumerate(chars) }\n",
    "itos = { i:ch for i,ch in enumerate(chars) }\n",
    "encode = lambda s: [stoi[c] for c in s] # encoder: transform a string into a list of integers\n",
    "decode = lambda l: ''.join([itos[i] for i in l]) # decoder: transform a list of integers into a string\n",
    "\n",
    "\n",
    "# test that your encoder/decoder is coherent\n",
    "testString = \"\\nDemain, dès l'aube\"\n",
    "assert decode(encode (testString)) ==  testString"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adf90d39",
   "metadata": {},
   "source": [
    "### Découpage Train/Validation\n",
    "\n",
    "L'objectif étant de prédire des poèmes, il ne faut pas mélanger les lignes aléatoirements. Il faut garder l'ordre des lignes dans le texte et uniquement prendre les premier 90% pour entrainer et les 10% restant pour contrôler l'apprentissage. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "1f88e9a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "# Train and test splits\n",
    "data = torch.tensor(encode(text), dtype=torch.long)\n",
    "## YOUR CODE HERE\n",
    "# first 90% will be train, rest val\n",
    "n = int(0.9*len(data))\n",
    "###\n",
    "train_data = data[:n]\n",
    "val_data = data[n:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06951737",
   "metadata": {},
   "source": [
    "### Contexte\n",
    "\n",
    "Le modèle de langue possède comme paramètre la taille maximale du contexte à considérer pour faire la prédiction du prochain caractère. Ce contexte est appelé `block_size`. Les données d'apprentissage sont donc des sequences de charactères consécutifs, issues de l'ensemble d'entraînenement tirées aléatoirement et de longueur `block_size`.\n",
    "\n",
    "Si le caractère de début de la séquence est `i`, la séquence de contexte est donc :\n",
    "``` x = data[i:i+block_size]```\n",
    "et la valeur à prédire à chaque position dans le contexte est le caractère suivant:\n",
    "```y  = [data[i+1:i+block_size+1]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "2740d760",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([21574])\n",
      "context is >r< target is >e<\n",
      "context is >re< target is > <\n",
      "context is >re < target is >v<\n",
      "context is >re v< target is >o<\n",
      "context is >re vo< target is >l<\n",
      "context is >re vol< target is >o<\n",
      "context is >re volo< target is >n<\n",
      "context is >re volon< target is >t<\n"
     ]
    }
   ],
   "source": [
    "block_size = 8\n",
    "\n",
    "i  = torch.randint(len(data) - block_size, (1,))\n",
    "print (i)\n",
    "x = train_data[i:i+block_size]\n",
    "y = train_data[i+1:i+1+block_size]\n",
    "\n",
    "for t in range(block_size):\n",
    "    context = x[:t+1]\n",
    "    target = y[t]\n",
    "    print (f'context is >{decode(context.tolist())}< target is >{decode([target.tolist()])}<')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69574e6a",
   "metadata": {},
   "source": [
    "### Définition des batchs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "07b5bbf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 4\n",
    "torch.manual_seed(2023)\n",
    "# data loading\n",
    "def get_batch(split):\n",
    "    # generate a small batch of data of inputs x and targets y\n",
    "    data = train_data if split == 'train' else val_data\n",
    "    # select batch_size starting points in the data, store them in a list called starting_points\n",
    "    starting_points = torch.randint(len(data) - block_size, (batch_size,))\n",
    "    # x is the sequence of integer starting at each straing point and of length block_size\n",
    "    x = torch.stack([data[i:i+block_size] for i in starting_points])\n",
    "    # y is the character after each starting position\n",
    "    y = torch.stack([data[i+1:i+block_size+1] for i in starting_points])\n",
    "    # send data and target to device\n",
    "    x, y = x.to(device), y.to(device)\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3645d40a",
   "metadata": {},
   "source": [
    "### Premier modèle: un bigramme \n",
    "\n",
    "Prédit le caractère suivant uniquement en fonction du caractère courant.\n",
    "Optimisé par descente de gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "279ab480",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "# use a gpu if we have one\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "# super simple bigram model\n",
    "class BigramLanguageModel(nn.Module):\n",
    "\n",
    "    def __init__(self, vocab_size):\n",
    "        super().__init__()\n",
    "        # we use a simple vocab_size times vocab_size tensor to store the probabilities \n",
    "        # of each token given a single token as context\n",
    "        self.token_embedding_table = nn.Embedding(vocab_size, vocab_size)\n",
    "\n",
    "    def forward(self, idx, targets=None):\n",
    "\n",
    "        # idx and targets are both (Batch,Time) tensor of integers\n",
    "        logits = self.token_embedding_table(idx) # (Batch,Time,Channel)\n",
    "   \n",
    "        # don't compute loss if we don't have targets\n",
    "        if targets is None:\n",
    "            loss = None\n",
    "        else:\n",
    "            # change the shape of the logits and target to match what is needed for CrossEntropyLoss\n",
    "            # https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html\n",
    "            Batch, Time, Channels = logits.shape\n",
    "            logits = logits.view(Batch*Time, Channels)\n",
    "            targets = targets.view(Batch*Time)\n",
    "            \n",
    "            # negative log likelihood between prediction and target\n",
    "            loss = nn.functional.cross_entropy(logits, targets)\n",
    "\n",
    "        return logits, loss\n",
    "\n",
    "    def generate(self, idx, max_new_tokens):\n",
    "        # idx is (B, T) array of indices in the current context\n",
    "        for _ in range(max_new_tokens):\n",
    "            # get the predictions\n",
    "            logits, loss = self(idx)\n",
    "            # focus only on the last time step\n",
    "            logits = logits[:, -1, :] # becomes (B, C)\n",
    "            # apply softmax to get probabilities\n",
    "            probs = nn.functional.softmax(logits, dim=-1) # (B, C)\n",
    "            # sample from the distribution\n",
    "            idx_next = torch.multinomial(probs, num_samples=1) # (B, 1)\n",
    "            # append sampled index to the running sequence\n",
    "            idx = torch.cat((idx, idx_next), dim=1) # (B, T+1)\n",
    "        return idx\n",
    "\n",
    "model = BigramLanguageModel(vocab_size)\n",
    "# send the model to device\n",
    "m = model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cdae510",
   "metadata": {},
   "source": [
    "Les poids étant unitialisés avec une distribution normale N(0,1) sur chaque dimension, la loss attendue après l'initialisation est `-ln(1/vocab_size)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "eeef5ef4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 101])\n",
      "tensor(5.0953, grad_fn=<NllLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "xb, yb = get_batch('train')\n",
    "logits, loss = m(xb, yb)\n",
    "print (logits.shape)\n",
    "print (loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "b541e679",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 8, 16])\n"
     ]
    }
   ],
   "source": [
    "print (out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "307c84fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3]\n",
      "tensor([[3]])\n",
      "N)G(F(ÎG7\n",
      "\n",
      ";Ww«ïIKK[G9bÀB;7ÔZU5pWt3?îzê\n",
      "Zû7àâËZ!5-F[HëK«mxMLWÉn8ÆSê_Rïcx.7P)(Ca5î.d-eZEn,jfJF8,U3ÂdOè\n"
     ]
    }
   ],
   "source": [
    "print (encode(['\\n']))\n",
    "print (idx)\n",
    "prompt = torch.ones((1,1), dtype=torch.long, device=device)*6\n",
    "print (decode(m.generate(prompt,max_new_tokens=100)[0].tolist()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "901a620d",
   "metadata": {},
   "source": [
    "### Entrainement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "e83bee5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0: train loss 2.3970, val loss 2.4571\n",
      "step 20: train loss 2.4051, val loss 2.4683\n",
      "step 40: train loss 2.4035, val loss 2.4442\n",
      "step 60: train loss 2.4001, val loss 2.4668\n",
      "step 80: train loss 2.3817, val loss 2.4844\n"
     ]
    }
   ],
   "source": [
    "max_iters = 100\n",
    "batch_size = 32\n",
    "eval_interval = 20\n",
    "learning_rate = 1e-3\n",
    "eval_iters = 20\n",
    "\n",
    "@torch.no_grad() # no gradient is computed here\n",
    "def estimate_loss():\n",
    "    out = {}\n",
    "    model.eval()\n",
    "    for split in ['train', 'val']:\n",
    "        losses = torch.zeros(eval_iters)\n",
    "        for k in range(eval_iters):\n",
    "            X, Y = get_batch(split)\n",
    "            logits, loss = model(X, Y)\n",
    "            losses[k] = loss.item()\n",
    "        out[split] = losses.mean()\n",
    "    model.train()\n",
    "    return out\n",
    "\n",
    "# create a PyTorch optimizer\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n",
    "\n",
    "for iter in range(max_iters):\n",
    "\n",
    "    # every once in a while evaluate the loss on train and val sets\n",
    "    if iter % eval_interval == 0:\n",
    "        losses = estimate_loss()\n",
    "        print(f\"step {iter}: train loss {losses['train']:.4f}, val loss {losses['val']:.4f}\")\n",
    "\n",
    "    # sample a batch of data\n",
    "    xb, yb = get_batch('train')\n",
    "\n",
    "    # evaluate the loss\n",
    "    logits, loss = model(xb, yb)\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "7b96e439",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Hécen pr,  drmmou des lent d, êt'he le pit e, mes sple ls fêmafans.\n",
      " quie-t  pait, e, t rt   d  yrp\n"
     ]
    }
   ],
   "source": [
    "idx = torch.ones((1,1), dtype=torch.long)*3\n",
    "print (decode(m.generate(idx,max_new_tokens=100)[0].tolist()))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0a03ad8a",
   "metadata": {},
   "source": [
    "## Single Head Attention\n",
    "\n",
    "\n",
    "\n",
    "![single head attention](images/single_head_attention.png)\n",
    "\n",
    "\n",
    "Le futur n'est pas utilisé pour prédire (le futur)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "0534eba8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[4.8368e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "         [2.0541e-01, 2.6684e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "         [1.9503e-01, 1.4916e-01, 4.8819e-01, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "         [2.9977e-02, 3.8200e-01, 1.0825e-01, 3.8721e-02, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "         [1.2269e-02, 3.6319e-02, 1.6390e-01, 1.1026e-02, 5.1437e-01,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "         [4.7134e-03, 9.5730e-02, 9.7573e-02, 3.9572e-01, 1.1593e-01,\n",
      "          4.6665e-02, 0.0000e+00, 0.0000e+00],\n",
      "         [3.9678e-02, 6.1178e-02, 4.8630e-02, 2.1766e-02, 3.5506e-01,\n",
      "          9.2121e-01, 5.7621e-01, 0.0000e+00],\n",
      "         [2.9240e-02, 8.7719e-03, 9.3462e-02, 5.3277e-01, 1.4638e-02,\n",
      "          3.2123e-02, 4.2379e-01, 1.0000e+00]],\n",
      "\n",
      "        [[2.7494e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "         [1.1741e-01, 4.3052e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "         [2.4072e-01, 1.2725e-02, 2.6484e-01, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "         [1.7417e-01, 5.2141e-02, 4.7031e-02, 6.6376e-01, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "         [3.4500e-04, 5.3654e-02, 1.3440e-01, 1.6586e-02, 8.9560e-01,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "         [1.5693e-01, 4.5553e-02, 6.5470e-02, 8.8662e-02, 6.8136e-02,\n",
      "          5.9788e-01, 0.0000e+00, 0.0000e+00],\n",
      "         [5.5300e-03, 1.7223e-02, 2.7298e-01, 1.8437e-01, 1.1272e-03,\n",
      "          7.7876e-02, 9.1063e-01, 0.0000e+00],\n",
      "         [2.9956e-02, 3.8819e-01, 2.1529e-01, 4.6618e-02, 3.5137e-02,\n",
      "          3.2425e-01, 8.9373e-02, 1.0000e+00]],\n",
      "\n",
      "        [[4.2840e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "         [3.1575e-01, 2.5673e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "         [1.4774e-01, 8.5728e-02, 4.8579e-01, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "         [4.6786e-02, 2.8696e-01, 1.4634e-01, 3.6446e-01, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "         [3.8960e-02, 9.9197e-02, 8.0961e-02, 4.2863e-02, 4.9366e-01,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "         [5.9949e-03, 1.1154e-01, 2.8337e-02, 2.4932e-01, 3.5326e-01,\n",
      "          1.7750e-01, 0.0000e+00, 0.0000e+00],\n",
      "         [5.4208e-03, 1.1845e-01, 1.2734e-01, 3.4360e-02, 3.7149e-03,\n",
      "          4.7535e-01, 9.0130e-01, 0.0000e+00],\n",
      "         [1.0938e-02, 4.1390e-02, 1.3123e-01, 3.0899e-01, 1.4936e-01,\n",
      "          3.4715e-01, 9.8703e-02, 1.0000e+00]],\n",
      "\n",
      "        [[5.3479e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "         [1.5249e-01, 3.0796e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "         [6.9083e-02, 2.0919e-01, 2.3404e-01, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "         [4.7981e-02, 2.6005e-01, 6.0963e-02, 2.9563e-01, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "         [3.8701e-02, 8.3968e-02, 1.0070e-01, 1.2813e-01, 7.2840e-01,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "         [7.6431e-02, 1.9349e-02, 2.0515e-01, 1.2629e-01, 1.8610e-01,\n",
      "          4.9453e-01, 0.0000e+00, 0.0000e+00],\n",
      "         [2.8011e-02, 6.5096e-02, 3.7148e-01, 1.2864e-02, 5.1977e-03,\n",
      "          2.5470e-01, 1.5613e-01, 0.0000e+00],\n",
      "         [5.2516e-02, 5.4377e-02, 2.7667e-02, 4.3708e-01, 8.0304e-02,\n",
      "          2.5077e-01, 8.4387e-01, 1.0000e+00]]], grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "T = 8\n",
    "\n",
    "# first version of the contraints with matrix multiplication\n",
    "weights0 = torch.tril(torch.ones(T,T))\n",
    "weights0 = weights / weights.sum(1, keepdim=True) \n",
    "print (weights0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "ab2268f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.5000, 0.5000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.3333, 0.3333, 0.3333, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.2500, 0.2500, 0.2500, 0.2500, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.1667, 0.1667, 0.1667, 0.1667, 0.1667, 0.1667, 0.0000, 0.0000],\n",
      "        [0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.0000],\n",
      "        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250]])\n"
     ]
    }
   ],
   "source": [
    "tril = torch.tril(torch.ones(T,T))\n",
    "weights = weights.masked_fill(tril== 0, float('-inf'))\n",
    "weights = nn.functional.softmax(weights, dim=-1)\n",
    "print (weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "bed1f70a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a2654490",
   "metadata": {},
   "source": [
    "Attention head\n",
    "\n",
    "* créer les couches key, query et value comme des couches linéaires de dimension C x head_size\n",
    "* appliquer les couches à x\n",
    "* weights = query x key (transposer les deuxième et troisième dimensions de key pour pouvoir faire le produit)\n",
    "* appliquer le facteur de normalisation \n",
    "* appliquer le masque triangulaire  et la softmax à weight\n",
    "* appliquer value à x\n",
    "* le résultat `out` est la multiplication de weights par value(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "fe9164fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "head_size = 16\n",
    "B, T, C = 4, 8, 32\n",
    "x = torch.randn(B, T, C)\n",
    "key = nn.Linear(C, head_size, bias=False)\n",
    "query =  nn.Linear(C, head_size, bias=False)\n",
    "value =  nn.Linear(C, head_size, bias=False)\n",
    "k = key(x) # (B, T, head_size)\n",
    "q = query(x) # (B, T, head_size)\n",
    "v = value(x) # (B, T, head_size)\n",
    "weights = q @ k.transpose(1, 2) * head_size**-0.5 # (B, T, head_size) @ (B, 16, head_size) -> (B, T, T)\n",
    "weights = weights.masked_fill(tril== 0, float('-inf'))\n",
    "weights = nn.functional.softmax(weights, dim=-1)\n",
    "out  = weights @ value(x) # (B, T, head_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "1978bf51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-4.8218e-01, -1.6254e-01,  4.6861e-02, -1.1899e-01, -4.8324e-01,\n",
       "         -5.2388e-01,  6.5677e-03, -5.3459e-02,  2.7850e-01, -4.1425e-01,\n",
       "         -3.3740e-01,  1.5587e-01, -2.5850e-01,  2.1828e-01,  7.7525e-03,\n",
       "          3.7400e-01],\n",
       "        [ 5.8942e-01,  1.1879e-02,  3.4260e-01,  4.2746e-01, -4.6086e-01,\n",
       "         -4.5144e-01, -4.6541e-01, -1.6498e-01,  3.2426e-01, -5.3940e-02,\n",
       "          1.3195e-02,  5.8804e-02, -4.8058e-01,  5.2046e-01,  3.5556e-01,\n",
       "          1.9390e-01],\n",
       "        [ 2.5004e-01,  1.2970e-02, -7.3553e-02,  4.0934e-01, -3.9027e-01,\n",
       "         -3.6913e-01, -2.9485e-01, -9.4224e-02,  2.2517e-02, -1.4430e-01,\n",
       "          1.1435e-01,  5.0670e-02, -5.0698e-01,  4.4101e-01,  2.7340e-01,\n",
       "          1.8484e-01],\n",
       "        [ 1.0507e+00,  9.5079e-02,  4.1365e-01,  7.0172e-01, -3.9971e-01,\n",
       "         -3.4922e-01, -6.4075e-01, -2.0988e-01,  2.2971e-01,  1.1620e-01,\n",
       "          2.4551e-01,  6.4572e-04, -5.7112e-01,  6.7137e-01,  5.3380e-01,\n",
       "          7.7160e-02],\n",
       "        [-1.9791e-01,  2.8440e-01, -3.4490e-01, -1.0740e-01, -8.1851e-01,\n",
       "         -2.5128e-01, -4.5937e-01, -5.2786e-01,  5.4026e-01,  5.3357e-01,\n",
       "          7.6078e-01,  8.9848e-01,  6.1346e-01,  3.0132e-01, -1.8718e-01,\n",
       "          3.2629e-01],\n",
       "        [-3.6089e-01, -8.2311e-02,  8.6125e-02, -2.3460e-02, -2.0064e-01,\n",
       "          3.8336e-02,  1.0925e-01, -2.1629e-01, -2.0981e-01, -7.7949e-02,\n",
       "          3.0638e-01,  2.3709e-01,  1.8457e-01,  4.3078e-01,  2.0910e-01,\n",
       "          1.0173e-01],\n",
       "        [-6.0827e-02,  4.0086e-01, -1.7643e-01, -8.9479e-02, -5.9185e-01,\n",
       "         -2.5654e-01, -4.8111e-01, -5.4897e-01,  4.1739e-01,  3.2707e-01,\n",
       "          4.7426e-01,  6.7836e-01,  3.4241e-01,  2.9268e-01, -1.5625e-01,\n",
       "          3.5451e-01],\n",
       "        [-7.6720e-01, -2.0007e-01,  6.6358e-02, -1.0570e-01,  1.3216e-01,\n",
       "          1.7350e-01,  4.5413e-01, -1.2728e-01, -5.1839e-01, -3.4743e-01,\n",
       "          1.1575e-01,  6.5975e-02,  1.3666e-01,  3.3635e-01,  1.7017e-01,\n",
       "          8.2308e-02]], grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights[0]\n",
    "out[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "554a4fdf",
   "metadata": {},
   "source": [
    "\n",
    "Questions:\n",
    "\n",
    "> * Copier votre code dans `gpt_single_head.py` et faite un entrainement.\n",
    "> * Quelle loss en train et val obtenez vous ? Le texte vous parait-il meilleur ?\n",
    "\n",
    "step 4999: train loss 2.3324, val loss 2.4422"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7df33f99",
   "metadata": {},
   "source": [
    "## Multi-head attention\n",
    "\n",
    "La *multi-head attention* est simplement le calcul en parallèle de plusieurs *single head attention*. Chacun des single head attention est concaténée pour créer la sortie de la multi-head attention. Dans la figure issue de l'article original, le nombre de *heads* dans le *multi-head* est `h`. Afin d'opérer des combinaisons pondées sur la sortie de chacune des single head, une couche de calcul linéaire est ajoutée.\n",
    "\n",
    "![multi head attention](images/multi_head_attention.png)\n",
    "\n",
    "Le code ci-dessous crée un module de multi-head attention.\n",
    "Question:\n",
    "> * dans le constructeur, créer une liste contenant `num_heads` module `Head` en utilisant la fonction [ModuleList](https://pytorch.org/docs/stable/generated/torch.nn.ModuleList.html) de pytorch \n",
    "> * dans la fonction `forward`, appliquer chaque single head à l'input et concaténer le résultat en utilisant la fonction [cat](https://pytorch.org/docs/stable/generated/torch.cat.html) de pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "d6de09b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    \"\"\" multiple heads of self-attention in parallel \"\"\"\n",
    "\n",
    "    def __init__(self, num_heads, head_size):\n",
    "        super().__init__()\n",
    "        ## YOUR CODE HERE\n",
    "        ## list of num_heads modules of type Head\n",
    "        self.heads = nn.ModuleList([Head(head_size) for _ in range(num_heads)])\n",
    "        ###\n",
    "        \n",
    "    def forward(self, x):\n",
    "        ## YOUR CODE HERE\n",
    "        ## apply each head in self.heads to x and concat the results \n",
    "        out = torch.cat([h(x) for h in self.heads], dim=-1)\n",
    "\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "041755f2",
   "metadata": {},
   "source": [
    "Questions:\n",
    "> * copier le fichier gpt_single_head.py en gpt_multi_head.py\n",
    "> * ajouter le module MultiHeadAttention dans gpt_multi_head.py\n",
    "> * en tête de fichier, ajouter un paramètre  `n_head = 4`\n",
    "> * dans le module BigramLanguageModel, remplacer le module Head par un module MultiHeadAttention avec la paramètres `num_heads = n_head` et `head_size = n_embd // n_head` pour garder le même nombre de paramètres.\n",
    "> relancer l'entrainement et noter le nombre de paramètres et les loss obtenues\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3ef85df",
   "metadata": {},
   "outputs": [],
   "source": [
    "0.009893 M parameters\n",
    "step 4999: train loss 2.1570, val loss 2.1802"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99e48baf",
   "metadata": {},
   "source": [
    "## Ajout d'une couche de calcul FeedForward\n",
    "\n",
    "\n",
    "Après les couches d'attention qui collectent l'information dans la séquence, une couche de calcul est ajoutée pour combiner toutes les informations de la séquence. Cette couche est un simple Multi-Layer-Perceptron avec une couche cachée et une non linéarité de type [RELU](https://pytorch.org/docs/stable/generated/torch.nn.ReLU.html)\n",
    "![multi feedfoward](images/multi_ff.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "07707a61",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedForward(nn.Module):\n",
    "    \"\"\" a simple MLP with RELU \"\"\"\n",
    "\n",
    "    def __init__(self, n_embd):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(n_embd, n_embd),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10e0c0a9",
   "metadata": {},
   "source": [
    "Question\n",
    "> * ajouter le module `FeedForward` dans gpt_multi_head.py\n",
    "> * ajouter cette couche `FeedForward` après la *multi-head attention*\n",
    "> * relancer l'entrainement et noter le nombre de paramètres et les loss obtenues"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0af8429e",
   "metadata": {},
   "source": [
    "0.010949 M parameters\n",
    "step 4999: train loss 2.1290, val loss 2.1216"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a41a8da",
   "metadata": {},
   "source": [
    "## Empiler les blocs\n",
    "\n",
    "Le réseau construit jusqu'à présent n'est en fait qu'un bloc du réseau final. Il est maintenant possible d'empiler les blocs de *multi-head attention* pour créer un réseau profond. \n",
    "\n",
    "![multi feedfoward](images/multi_bloc.png)\n",
    "\n",
    "\n",
    "Le code suivant crée un bloc : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "31cd5827",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Block(nn.Module):\n",
    "    \"\"\" A single bloc of multi-head attention \"\"\"\n",
    "\n",
    "    def __init__(self, n_embd, n_head):\n",
    "        super().__init__()\n",
    "        head_size = n_embd // n_head\n",
    "        self.sa = MultiHeadAttention(n_head, head_size)\n",
    "        self.ffwd = FeedForward(n_embd)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.sa(x)\n",
    "        x = self.ffwd(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8f07dae",
   "metadata": {},
   "source": [
    "Question\n",
    "> * ajouter le module `Block` dans gpt_multi_head.py\n",
    "> * modifier le code de `BigramLanguageModel` pour ajouter 3 `Block(n_embd, n_head=4)` avec un contaier [Sequential](https://pytorch.org/docs/stable/generated/torch.nn.Sequential.html) à la place de `MultiHeadAttention`et `FeedForward`\n",
    "> * relancer l'entrainement et noter le nombre de paramètres et les loss obtenues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29d5d708",
   "metadata": {},
   "outputs": [],
   "source": [
    "0.019205 M parameters\n",
    "step 4999: train loss 2.2080, val loss 2.2213"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de4bb026",
   "metadata": {},
   "source": [
    "## Amélioration de l'entraînement\n",
    "\n",
    "Si on veut continuer à augmenter la taille du réseau, il est nécessaire d'utiliser des couches permettant d'améliorer l'entraînement et ses capacités de généralisation (réduire le sur-apprentissage). Ces couches sont :\n",
    "- *skip connections* ou *residual connections*\n",
    "- les couches de normalisation\n",
    "- le dropout\n",
    "\n",
    "\n",
    "![multi feedfoward](images/multi_skip_norm.png)\n",
    "\n",
    "\n",
    "Questions:\n",
    "> * dans le module Bloc, ajouter une skip connection en ajoutant l'input dans chaque connexion: \n",
    "```\n",
    "        x = x + self.sa(self.ln1(x))\n",
    "        x = x + self.ffwd(self.ln2(x))\n",
    "```\n",
    "> * dans le module Bloc, ajouter 2 couches de [LayerNorm](https://pytorch.org/docs/stable/generated/torch.nn.LayerNorm.html) de taille `n_embd` avant la couche de *Multi-Head attention* et avant la *FeedForward*\n",
    "> * après la série de 3 blocs, ajouter une couche de LayerNorm de taille `n_embd` \n",
    "> * définir une variable `dropout = 0.2` en début de fichier et ajouter une couche de [Dropout](https://pytorch.org/docs/stable/generated/torch.nn.Dropout.html)\n",
    ">    * après la couche RELU dans FeedForward\n",
    ">    * après la couche de MultiHead dans `MultiHeadAttention`\n",
    ">    * après la softmax dans la single head attention `Head`\n",
    "> * relancer l'entrainement et noter le nombre de paramètres et les loss obtenues\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a60d39b",
   "metadata": {},
   "outputs": [],
   "source": [
    "0.019653 M parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3d7e8aa",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "Les principaux éléments de GPT2 sont en place, il faut maintenant faire passer le modèle à l'échelle et l'entraîner sur une base de données beaucoup plus grande. Pour comparaison, les paramètres de [GPT2](https://huggingface.co/transformers/v2.11.0/model_doc/gpt2.html) sont : \n",
    "\n",
    "* `vocab_size = 50257` : GPT2 modélise des token (subword) alors que nous modélisons des caractères. Pour nous, `vocab_size = 100`\n",
    "* `n_positions = 1024` : la taille maximale du contexte. Pour nous, c'est `block_size = 8`\n",
    "* `n_embd = 768`:  la dimension des embeddings. Pour nous c'est `n_embd = 32`\n",
    "* `n_layer = 12`: le nombre de block. Pour nous c'est 3.\n",
    "* `n_head = 12`: le nombre de multi-head attention. Pour nous c'est 4.\n",
    "\n",
    "Au total, GPT2 a 1500 millions de paramètres et a été entrainé sur 8M de pages web, soit 40 Gb de texte.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2c0d9d9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lm-env",
   "language": "python",
   "name": "lm-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
